<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>James Uanhoro on James Uanhoro</title>
    <link>https://www.jamesuanhoro.com/</link>
    <description>Recent content in James Uanhoro on James Uanhoro</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 James Uanhoro</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Using glmer() to perform Rasch analysis</title>
      <link>https://www.jamesuanhoro.com/post/rasch_binary_using_glmer/</link>
      <pubDate>Tue, 02 Jan 2018 10:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/rasch_binary_using_glmer/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;ve been interested in the relationship between ordinal regression and item response theory for a few months now. There are several helpful papers on the topic, here are some randomly picked ones &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;, and a book.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; In this post, I focus on Rasch analysis. To do any of these analyses as a regression, your data need to be in long format - single column identifying items (regression predictor), single column with item response categories (regression outcome), and column holding the person ID. Using the right dummy coding of the variables, you can get so-called &lt;em&gt;item difficulties&lt;/em&gt; as regression coefficients for the items - more on this later.&lt;/p&gt;

&lt;p&gt;Most recently, I spent some type trying to understand (in English) the different estimation methods. The clearest reading I found is the Software chapter of De Boeck &amp;amp; Wilson&amp;rsquo;s Explanatory item response models, the final chapter.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:6&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; I&amp;rsquo;ve learned a few things. The three most common estimation methods are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Joint maximum likelihood (JML): To do this, you include both the items and the persons as dummy variables in the model predicting the responses, and apply ordinal logistic regression. You &amp;ldquo;maximize the likelihood&amp;rdquo; of both item and person measures, hence the &amp;ldquo;joint&amp;rdquo; in the joint maximum likelihood. Things can get unwieldy (bonkers) pretty quickly; if you have a thousand persons, you have 999 dummies for persons. And it seems to be the least recommended of the three estimation methods.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Conditional logistic regression, referred to as conditional maximum likelihood (CML) in the measurement literature. This method treats the individual effects as nuisance parameters (intercepts disappear from model), and is the closest you get to so-called &amp;ldquo;person-free&amp;rdquo; item measures in Rasch analysis. Thing is, it does not use all of the data; only individuals whose responses vary contribute to the estimation (perfect pass or fail are discarded). So you have the sample size loss resulting in &lt;em&gt;inefficient variance estimation&lt;/em&gt; (larger standard errors). Additionally, you cannot obtain predicted values from this model, as the intercept is gone. A common method to obtain person intercepts measurement folks have come up with: use the item coefficients from CML in JML as the item coefficients, then estimate coefficients for person dummy codes.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Standard multilevel model, referred to as marginal maximum likelihood (MML) in the measurement literature. Item difficulties are item fixed effects, and person abilities are random intercepts. Essentially, this is the simplest multilevel model you could build.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After doing the reading, I decided to try out a Rasch analysis, produce several Rasch outputs.&lt;/p&gt;

&lt;h2 id=&#34;demonstration&#34;&gt;Demonstration&lt;/h2&gt;

&lt;p&gt;Following this demonstration probably requires good knowledge of ggplot2 and dplyr to create the plots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(eRm) # Standard Rasch analysis with CML estimation
library(glmmTMB) # Better for binary logistic regression than glmer, but does not accept contrasts. If you want your regression coefficients to be item difficulties on arrival, not good
# library(survival) # Handles conditional logistic regression, clogit(), but does not accept contrasts
library(Epi) # For conditional logistic regression with contrasts
library(lme4) # For glmer
library(ggplot2) # For plotting
library(ggrepel) # For plot labeling
library(dplyr) # For data manipulation
library(scales) # For formatted percent on ggplot axes

# Data comes from eRm package, it is simulated, has 30 items and 100 persons, binary response format
raschdat1 &amp;lt;- as.data.frame(raschdat1)

# CML estimation using eRm package
res.rasch &amp;lt;- RM(raschdat1)
# Coefficients are item &amp;quot;easiness&amp;quot;, need to multiply by -1 to obtain difficulties
coef(res.rasch)

beta V1      beta V2      beta V3      beta V4      beta V5
1.565269700  0.051171719  0.782190094 -0.650231958 -1.300578876
beta V6      beta V7      beta V8      beta V9     beta V10
0.099296282  0.681696827  0.731734160  0.533662275 -1.107727126
beta V11     beta V12     beta V13     beta V14     beta V15
-0.650231959  0.387903893 -1.511191830 -2.116116897  0.339649394
beta V16     beta V17     beta V18     beta V19     beta V20
-0.597111141  0.339649397 -0.093927362 -0.758721132  0.681696827
beta V21     beta V22     beta V23     beta V24     beta V25
0.936549373  0.989173502  0.681696830  0.002949605 -0.814227487
beta V26     beta V27     beta V28     beta V29     beta V30
1.207133468 -0.093927362 -0.290443234 -0.758721133  0.731734150

# Repeating using regression
raschdat1.long &amp;lt;- raschdat1
raschdat1.long$tot &amp;lt;- rowSums(raschdat1.long) # Create total score
c(min(raschdat1.long$tot), max(raschdat1.long$tot)) # Min and max score

[1]  1 26

raschdat1.long$ID &amp;lt;- 1:nrow(raschdat1.long) # create person ID
raschdat1.long &amp;lt;- tidyr::gather(raschdat1.long, item, value, V1:V30) # Wide to long
# Make item factor
raschdat1.long$item &amp;lt;- factor(
  raschdat1.long$item, levels = paste0(&amp;quot;V&amp;quot;, 1:30), ordered = TRUE)

# Conditional maximum likelihood
# Use clogistic() function in Epi package, note the contrasts
res.clogis &amp;lt;- clogistic(
  value ~ item, strata = ID, raschdat1.long,
  contrasts = list(item = rbind(rep(-1, 29), diag(29))))
# Regression coefficients
coef(res.clogis)

item1        item2        item3        item4        item5
0.051193209  0.782190560 -0.650241362 -1.300616876  0.099314453
item6        item7        item8        item9       item10
0.681691285  0.731731557  0.533651426 -1.107743224 -0.650241362
item11       item12       item13       item14       item15
0.387896763 -1.511178125 -2.116137610  0.339645555 -0.597120333
item16       item17       item18       item19       item20
0.339645555 -0.093902568 -0.758728000  0.681691285  0.936556599
item21       item22       item23       item24       item25
0.989181510  0.681691285  0.002973418 -0.814232531  1.207139323
item26       item27       item28       item29        
-0.093902568 -0.290430680 -0.758728000  0.731731557           

# Note that item1 is V2 not V1, and item29 is V30. The values correspond to the results from the eRm package. To obtain the easiness of the first item V1, simply sum the coefficients of the item1 to item29 and multiply by -1
sum(coef(res.clogis)[1:29]) * -1

[1] 1.565278

# A few more things to confirm both models are equivalent
res.rasch$loglik # Rasch log-likelihood

[1] -1434.482

res.clogis$loglik # conditional logsitic log-likelihood, second value is log-likelihood of final model

[1] -1630.180 -1434.482

# One can also compare confidence intervals, variances, ...

# clogistic allows you to check the actual sample size for the analysis using:
res.clogis$n

[1] 3000

# Aparently, all of the data (30 * 100) were used in the estimation. This is because no participant scored zero on all questions, or 1 on all questions (minimum was 1 and maximum was 26 out of 30). All the data contributed to estimation, so the variance estimation in this example was efficient(?)

# Estimation using joint maximum likelihood
# Standard logistic regression, note the use of contrasts
res.jml &amp;lt;- glm(
  value ~ item + factor(ID), data = raschdat1.long, family = binomial,
  contrasts = list(item = rbind(rep(-1, 29), diag(29))))
# First thirty coefficients
coef(res.jml)[1:30]

(Intercept)        item1        item2        item3        item4
-3.688301292  0.052618523  0.811203577 -0.674538589 -1.348580496
      item5        item6        item7        item8        item9
0.102524596  0.706839644  0.758800752  0.553154545 -1.148683041
     item10       item11       item12       item13       item14
-0.674538589  0.401891360 -1.566821260 -2.193640539  0.351826379
     item15       item16       item17       item18       item19
-0.619482689  0.351826379 -0.097839229 -0.786973625  0.706839644
     item20       item21       item22       item23       item24
0.971562267  1.026247034  0.706839644  0.002613624 -0.844497142
     item25       item26       item27       item28       item29
1.252837340 -0.097839229 -0.301589647 -0.786973625  0.758800752

# item29 is the same as V30. Note that they are very similar to the coefficients from the eRm package. Differences result from differences in estimation method. To obtain the easiness of the first item V1, simply sum the coefficients of the item1 to item29 and multiply by -1
sum(coef(res.jml)[2:30]) * -1

[1] 1.625572

# Multilevel logistic regression or MML
# glmer does not converge with the data. glmmTMB does. But I want the regression coefficients to be item difficulties/easiness on arrival, and glmmTMB does not provide an option for contrasts. What I do is run glmer twice, with the fixed effects and random effects from the first run as starting values in the second run
res.mlm.l &amp;lt;- glmer(
  value ~ item + (1 | ID), raschdat1.long, family = binomial,
  contrasts = list(item = rbind(rep(-1, 29), diag(29))))
# Warning message:
# In checkConv(attr(opt, &amp;quot;derivs&amp;quot;), opt$par, ctrl = control$checkConv,  :
#   Model failed to converge with max|grad| = 0.00134715 (tol = 0.001, component 1)

# No warning after this :)
res.mlm.l &amp;lt;- glmer(
  value ~ item + (1 | ID), raschdat1.long, family = binomial,
  contrasts = list(item = rbind(rep(-1, 29), diag(29))),
  start = list(fixef = fixef(res.mlm.l), theta = getME(res.mlm.l, &amp;quot;theta&amp;quot;)))

## NOW the estimation stuff is out of the way, to the fun stuff
# I&#39;ll use the multilevel model to replicate the Rasch results
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Person-Item map

# eRm provides a person-item map with a single line:
plotPImap(res.rasch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/pimap.png&#34; alt=&#34;PIMAP&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# To create this map, we need item difficulties (regression coefficients * -1) and person abilities (random intercepts)
item.diff &amp;lt;- -1 * coef(summary(res.mlm.l))[, 1] # Regression coefficients * -1
item.diff[1] &amp;lt;- -1 * sum(item.diff[2:30]) # Difficulty of first item is sum of all others
item.diff &amp;lt;- data.frame(
  item.diff = as.numeric(item.diff), item = paste0(&amp;quot;V&amp;quot;, 1:30))
head(item.diff, 3) # What have we done?

    item.diff item
1 -1.56449994   V1
2 -0.05166222   V2
3 -0.78247594   V3

item.diff$move &amp;lt;- 1:30 # Cosmetic move to help me when creating PI chart

# For person abilities
pers.ab.df &amp;lt;- data.frame(pers.ability = ranef(res.mlm.l)$ID[, 1])

# GGPLOT-ING
ggplot(pers.ab.df, aes(x = pers.ability)) +
  geom_histogram(aes(y = ..count..), binwidth = .02, colour = 1) +
  geom_segment(mapping = aes(x = item.diff, xend = item.diff, yend = -.25),
               data = data.frame(item.diff), y = 0, linetype = 1) +
  geom_point(mapping = aes(x = item.diff, y = -.75 - move / 2),
            data = data.frame(item.diff), size = 1) +
  scale_y_continuous(breaks = c((-.75 + (-30:-1)/2), 0:8),
                     labels = c(paste0(&amp;quot;V&amp;quot;, 30:1), 0:8)) +
  geom_hline(yintercept = c(-.75 + seq(-29, 0, 2)/2), linetype = 3, size = .5) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(-4, 4, .5)) +
  labs(x = &amp;quot;Latent dimension&amp;quot;, y = &amp;quot;&amp;quot;, title = &amp;quot;Person-item map&amp;quot;) +
  theme_classic() +
  geom_label(label = &amp;quot;Distribution of person ability&amp;quot;, x = -1.8, y = 8) +
  theme(axis.title.y = element_text(hjust = 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/pimap_mlm.png&#34; alt=&#34;PIMAP_MLM&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# The extreme person scores are different. This is down to differences in MML and whatever method eRm uses to obtain person measures. It has to use a two-step process of sorts because CML does not provide person measures.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Item-Characteristic Curves

# eRm provides a item characteristic curves with a single line:
plotjointICC(res.rasch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/icc_joint.png&#34; alt=&#34;ICC&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Here, we need to be able to predict the probability that a student will get an item correct, given their latent ability. What I did was use the logistic equation to predict probabilities. The log-odds given a latent ability is the difference between a latent ability and an item difficulty. Once this log-odds is obtained, calculating the predicted probability is easy. Since I&#39;m using loops to do this, I also calculate item information, which is predicted probability multiplied by 1 - predicted probability. Here&#39;s how:
{
  theta.s &amp;lt;- seq(-6, 6, .01) # Person abilities for prediction
  pred.prob &amp;lt;- c() # Vector to hold predicted probabilities
  test.info.df &amp;lt;- c() # Vector to hold test info
  for (i in theta.s) { # Loop through abilities
    for (j in 1:30) { # Loop through items
      l &amp;lt;- i - item.diff$item.diff[j] # log-odds is ability - difficulty
      l &amp;lt;- exp(-l) # Exponentiate -log-odds
      l &amp;lt;- 1 / (1 + l) # Calculate predicted probability
      pred.prob &amp;lt;- c(pred.prob, l) # Store predicted probability
      l &amp;lt;- l * (1 - l) # Calculate test information
      test.info.df &amp;lt;- c(test.info.df, l) # Store test information
    }
  }
  # Save it all to data frame
  test.info.df &amp;lt;- data.frame(
    theta = sort(rep(theta.s, 30)),
    item = rep(paste0(&amp;quot;V&amp;quot;, 1:30), length(theta.s)),
    info = test.info.df,
    prob = pred.prob,
    diff = item.diff$item.diff
  )
  rm(i, j, theta.s, pred.prob, l) # Clean environment
}

## GGPLOT-ING
ggplot(test.info.df, aes(x = theta, y = prob, colour = reorder(item, diff, mean))) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  scale_x_continuous(breaks = -6:6, limits = c(-4, 4)) +
  labs(x = &amp;quot;Person ability&amp;quot;, y = &amp;quot;Probability of correct response&amp;quot;, colour = &amp;quot;Item&amp;quot;,
       title = &amp;quot;Joint item characteristic plot&amp;quot;) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/icc_joint_mlm.png&#34; alt=&#34;ICC_MLM&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# I find the colours ambiguous, this code would an item by item plot, not printed
ggplot(test.info.df, aes(x = theta, y = prob)) + geom_line() +
  scale_x_continuous(breaks = seq(-6, 6, 2), limits = c(-4, 4)) +
  scale_y_continuous(labels = percent, breaks = seq(0, 1, .25)) +
  labs(x = &amp;quot;Person ability&amp;quot;, y = &amp;quot;Probability of correct response&amp;quot;,
       title = &amp;quot;Item characteristic plot&amp;quot;,
       subtitle = &amp;quot;Items ordered from least to most difficult&amp;quot;) +
  facet_wrap(~ reorder(item, diff, mean), ncol = 10) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Person parameter plot

# Again, a one-liner in eRm:
plot(person.parameter(res.rasch))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/pp.png&#34; alt=&#34;PERS_PAR&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Compared to others, this is fairly straightforward. We need the estimated person abilities:
raschdat1.long$ability &amp;lt;- ranef(res.mlm.l)$ID[, 1]

# And GGPLOT-ING IT:
ggplot(raschdat1.long, aes(x = tot, y = ability)) +
  geom_point(shape = 1, size = 2) + geom_line() +
  scale_x_continuous(breaks = 1:26) +
  scale_y_continuous(breaks = round(c(
    min(raschdat1.long$ability),seq(-1.5, 1.5, .5),
    max(raschdat1.long$ability)), 2)) +
  labs(x = &amp;quot;Raw scores&amp;quot;, y = &amp;quot;Latent scores&amp;quot;, title = &amp;quot;Person parameter plot&amp;quot;) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/pp_mlm.png&#34; alt=&#34;PERS_PAR_MLM&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Both plots are not the same, though they overlap for the most part. Because estimation of person parameters is more tedious in CML, I&#39;d trust the multilevel values.

# Item fit using mean square

# eRm one-liner:
itemfit(person.parameter(res.rasch)) # Not printed

# First, we need fitted and residual values
raschdat1.long$fitted &amp;lt;- fitted(res.mlm.l)
raschdat1.long$resid &amp;lt;- resid(res.mlm.l, type = &amp;quot;response&amp;quot;)

# To calculate outfit MSQ:
raschdat1.long$o.msq &amp;lt;- (raschdat1.long$resid ^ 2) /
  (raschdat1.long$fitted * (1 - raschdat1.long$fitted))

# Summarize it by item using mean
item.diff$o.msq &amp;lt;- summarize(group_by(raschdat1.long, item),
                             o.msq = mean(o.msq))$o.msq

# To calculate infit MSQ:
item.diff$i.msq &amp;lt;- summarize(group_by(raschdat1.long, item), i.msq = sum(resid ^ 2) /
                              sum(fitted * (1 - fitted)))$i.msq

# Move everything into one data frame to compare using GGPLOT
{
  item.fit.df &amp;lt;- data.frame(
    item = paste0(&amp;quot;V&amp;quot;, 1:30), mml.osq = item.diff$o.msq, mml.isq = item.diff$i.msq,
    cml.osq = itemfit(person.parameter(res.rasch))$i.outfitMSQ,
    cml.isq = itemfit(person.parameter(res.rasch))$i.infitMSQ
  )
  item.fit.df &amp;lt;- cbind(
    tidyr::gather(item.fit.df[, 1:3], method.mml, mml, mml.osq:mml.isq),
    tidyr::gather(item.fit.df[, 4:5], method.cml, cml, cml.osq:cml.isq)
  )
  item.fit.df &amp;lt;- cbind(item.fit.df[, c(1, 3, 5)], method = c(
    rep(&amp;quot;Outfit MSQ&amp;quot;, 30), rep(&amp;quot;Infit MSQ&amp;quot;, 30)))
}

ggplot(item.fit.df, aes(x = mml, y = cml)) +
  scale_x_continuous(breaks = seq(0, 2, .1)) +
  scale_y_continuous(breaks = seq(0, 2, .1)) +
  geom_point(shape = 1) + geom_abline(slope = 1) + theme_classic() +
  geom_smooth(se = FALSE) + facet_wrap(~ method, ncol = 2) +
  labs(x = &amp;quot;glmer (MML)&amp;quot;, y = &amp;quot;eRm (CML)&amp;quot;, title = &amp;quot;Item fit comparing CML and MML&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/msq_comp_item.png&#34; alt=&#34;COMP_ITEM_FIT&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Interestingly, it seems the MSQ from CML is almost always higher than that from the multilevel model (MML)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Person fit using mean square

# eRm one-liner:
personfit(person.parameter(res.rasch)) # Not printed

pers.ab.df$ID &amp;lt;- 1:100

# Person outfit MSQ:
pers.ab.df$o.msq &amp;lt;- summarize(group_by(raschdat1.long, ID), o.msq = mean(o.msq))$o.msq

# Person infit MSQ:
pers.ab.df$i.msq &amp;lt;- summarize(group_by(raschdat1.long, ID), i.msq = sum(resid ^ 2) /
                                sum(fitted * (1 - fitted)))$i.msq

# Move everything into one data frame to compare using GGPLOT
{
  person.fit.df &amp;lt;- data.frame(
    ID = 1:100, mml.osq = pers.ab.df$o.msq, mml.isq = pers.ab.df$i.msq,
    cml.osq = personfit(person.parameter(res.rasch))$p.outfitMSQ,
    cml.isq = personfit(person.parameter(res.rasch))$p.infitMSQ
  )
  person.fit.df &amp;lt;- cbind(
    tidyr::gather(person.fit.df[, 1:3], method.mml, mml, mml.osq:mml.isq),
    tidyr::gather(person.fit.df[, 4:5], method.cml, cml, cml.osq:cml.isq)
  )
  person.fit.df &amp;lt;- cbind(person.fit.df[, c(1, 3, 5)], method = c(
    rep(&amp;quot;Outfit MSQ&amp;quot;, 100), rep(&amp;quot;Infit MSQ&amp;quot;, 100)))
}

ggplot(person.fit.df, aes(x = mml, y = cml)) +
  scale_x_continuous(breaks = seq(0, 2, .1)) +
  scale_y_continuous(breaks = seq(0, 2, .1)) +
  geom_point(shape = 1) + geom_abline(slope = 1) + theme_classic() +
  geom_smooth(se = FALSE) + facet_wrap(~ method, ncol = 2) +
  geom_text_repel(aes(
    label = ifelse(cml &amp;gt;= 1.5 | mml &amp;gt;= 1.5 | cml &amp;lt;= 0.5 | mml &amp;lt;= 0.5, ID, &amp;quot;&amp;quot;))) +
  geom_hline(yintercept = c(.5, 1.5), linetype = 2) +
  geom_vline(xintercept = c(.5, 1.5), linetype = 2) +
  labs(x = &amp;quot;glmer (MML)&amp;quot;, y = &amp;quot;eRm (CML)&amp;quot;, title = &amp;quot;Person fit comparing CML and MML&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/msq_comp_person.png&#34; alt=&#34;COMP_PERS_FIT&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Same pattern, MSQ from CML is almost always higher than that from the multilevel model (MML)
# I used the conventional cut-offs to identify misfitting persons
# Person 1 with low infit and outfit MSQ got only one question correct, cannot recall what stood out about 8, 26 and 53.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# TEST INFORMATION

# eRm one-liner:
plotINFO(res.rasch)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/iic_joint.png&#34; alt=&#34;IIC&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# We&#39;ve done the work for this above when we created the ICCs, and calculated the test information. All that remains is plotting.

# For the overall test information, we need to sum each items test information:
ggplot(summarise(group_by(test.info.df, theta), info = sum(info)),
       aes(x = theta, y = info)) + geom_line() +
  scale_x_continuous(breaks = -6:6) +
  scale_y_continuous(breaks = c(1:5, .10, 6.42)) +
  labs(x = &amp;quot;Person ability&amp;quot;, y = &amp;quot;Test information&amp;quot;, colour = &amp;quot;Item&amp;quot;,
       title = &amp;quot;Test information plot&amp;quot;) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/iic_joint_mlm.png&#34; alt=&#34;IIC_MLM&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# And the ambiguous colour plot:
ggplot(test.info.df, aes(x = theta, y = info)) +
  geom_line(aes(colour = reorder(item, diff, mean))) +
  scale_x_continuous(breaks = seq(-6, 6, 1)) +
  labs(x = &amp;quot;Person ability&amp;quot;, y = &amp;quot;Item information&amp;quot;, colour = &amp;quot;Item&amp;quot;,
       title = &amp;quot;Item information plot&amp;quot;,
       subtitle = &amp;quot;Items ordered from least to most difficult&amp;quot;) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/iic_overlay_mlm.png&#34; alt=&#34;IIC_OVER&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# And finally, using the Standard Error of Measurement (SEM), I thought you could create a confidence-band like plot. The SEM is the inverse of the root of test information.
ggplot(summarise(group_by(test.info.df, theta), info = 1 / sqrt(sum(info))),
       aes(x = theta)) +
  scale_x_continuous(breaks = seq(-3, 3, 1), limits = c(-3, 3)) +
  scale_y_continuous(breaks = c(seq(-3, 3, 1), -4.5, 4.5), limits = c(-4.5, 4.5)) +
  geom_line(aes(y = theta), size = .5) +
  geom_errorbar(aes(ymin = -1.96 * info + theta, ymax = 1.96 * info + theta), size = .05) +
  labs(x = &amp;quot;Estimated person ability&amp;quot;, y = &amp;quot;Range of 95% of true scores&amp;quot;) +
  geom_hline(yintercept = c(seq(-3, 3, 1), -4.5, 4.5), linetype = 1, size = .05) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/rasch_bin_logistic/sem.png&#34; alt=&#34;SEM&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# This is the one I like best, because I feel it is most informative. This plot shows that for a kid with an estimated ability of -3, their ability is estimated with such precision that their actual score could lie between -1.5 and -4.5. In the middle at 0, the actual score could lie between, by my guess, -.8 and .8. I am not so sure this interpretation is correct, but it is appealing :).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m not sure what I have achieved here, apart from a lot of ggplot-ing, &amp;hellip; But having worked through this, I feel I can better understand what the model is trying to claim a series of items, and what some of its diagnostics are about. I guess the next step would be to replicate this on real data I am working on. The &lt;code&gt;VGAM&lt;/code&gt; package is probably best for this, as it can perform several forms of ordinal regression. There is also the &lt;code&gt;ordinal&lt;/code&gt; package, but it only does cumulative logit regression.&lt;/p&gt;

&lt;p&gt;I have left out differential item functioning, but I believe that to be testing the fixed effects of groups in the data, and testing the interaction between test items and groups.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;P.S.: Rasch analysis is not just math (multilevel logistic regression, conditional logistic regression), it also seems to be a philosophy. So I guess the title here is misleading :). I have not used glmer() to perform Rasch analysis, I just created the outputs that support Rasch analysis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Rijmen, F., Tuerlinckx, F., De Boeck, P., &amp;amp; Kuppens, P. (2003). A nonlinear mixed model framework for item response theory. Psychological Methods, 8(2), 185–205. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.8.2.185&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1037/1082-989X.8.2.185&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;De Boeck, P., Bakker, M., Zwitser, R., Nivard, M., Hofman, A., Tuerlinckx, F., &amp;amp; Partchev, I. (2011). The Estimation of Item Response Models with the lmer Function from the lme4 Package in R. Journal Of Statistical Software, 39(12), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v039.i12&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.18637/jss.v039.i12&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Hedeker, D., Mermelstein, R. J., Demirtas, H., &amp;amp; Berbaum, M. L. (2016). A mixed-effects location-scale model for ordinal questionnaire data. Health Services and Outcomes Research Methodology, 16(3), 117–131. &lt;a href=&#34;https://doi.org/10.1007/s10742-016-0145-9&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1007/s10742-016-0145-9&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Engec, N. (1998). Logistic regression and item response theory: Estimation item and ability parameters by using logistic regression in IRT. ProQuest Dissertations and Theses. Retrieved from &lt;a href=&#34;http://digitalcommons.lsu.edu/gradschool_disstheses/6731&#34; target=&#34;_blank&#34;&gt;http://digitalcommons.lsu.edu/gradschool_disstheses/6731&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;Reise, S. P. (2000). Using mutlilevel logistic regression to evaluate person-fit in IRT models. Multivariate Behavioral Research, 35(4), 543–568. &lt;a href=&#34;https://doi.org/10.1207/S15327906MBR3504_06&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1207/S15327906MBR3504_06&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;De Boeck, P., &amp;amp; Wilson, M. (2004). Explanatory item response models : a generalized linear and nonlinear approach. (P. De Boeck &amp;amp; M. Wilson, Eds.). New York, NY: Springer New York. &lt;a href=&#34;https://doi.org/10.1007/978-1-4757-3990-9&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1007/978-1-4757-3990-9&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:6&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Chi-Square test of close fit in covariance-based SEM</title>
      <link>https://www.jamesuanhoro.com/post/chisq-test-close-fit/</link>
      <pubDate>Thu, 16 Nov 2017 10:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/chisq-test-close-fit/</guid>
      <description>

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;If you can assume close fit for the RMSEA, there is no reason why you cannot for a Chi-Square test in SEMs. The method to do this is relatively simple, and may cause SEM practitioners to reconsider the Chi-Square test.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;When assessing the fit of structural equation models, it is common for applied researchers to dismiss the $\chi^2$ test because it will almost always detect a statistically significant discrepancy between your model and the data, given a large enough sample size. This is because, almost always, our models are approximations of the data. If our model-implied covariance matrix actually matched the sample covariance matrix within sampling variability, the $\chi^2$ test would not be statistically significant regardless of sample size.&lt;/p&gt;

&lt;p&gt;Because of the sensitivity of the $\chi^2$ test to large sample sizes, practitioners often rely on other fit indices like the &lt;code&gt;RMSEA&lt;/code&gt;, &lt;code&gt;CFI&lt;/code&gt;, and &lt;code&gt;TLI&lt;/code&gt; - all of which are based on the $\chi^2$. For the RMSEA, MacCallum, Browne and Sugawara (1996)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; specified values of .05 and .08 as indicating close and mediocre&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; fit respectively. And in lavaan, you automatically get a test of close fit for the RMSEA with confidence intervals and a p-value. This test actually uses the $\chi^2$ distribution, and there is no reason why one cannot perform a $\chi^2$ test of close or mediocre fit depending on one&amp;rsquo;s standards.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The sections that follow may include details that not everyone would like to read about, you can skip to the &lt;a href=&#34;#lavaan&#34;&gt;bottom of the page for annotated lavaan code&lt;/a&gt; for how to compute a $\chi^2$ test of close or mediocre fit.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So the formula for the RMSEA is:&lt;/p&gt;

&lt;p&gt;$\sqrt{\frac{\chi^2-df}{df(N-1)}}$&lt;/p&gt;

&lt;p&gt;where $\chi^2$ is the $\chi^2$ test statistic of your model, $df$ is your model degrees of freedom, and $N$ is sample size.&lt;/p&gt;

&lt;p&gt;If your model fit the data perfectly, the numerator, $\chi^2-df$, is zero; this is the hypothesis the standard $\chi^2$-test tests. And to test this hypothesis, it uses the $\chi^2$-distribution. If we want to perform a test of close fit on the RMSEA, we do not assume a nil null distribution for the $\chi^2$. Instead, we use the non-central $\chi^2$ distribution with a non-centrality parameter that corresponds to an RMSEA of .05. The idea is we accept some level of misspecification, and we use a distribution that corresponds to this level of misspecification. Lavaan reports the result of this test as one of the fit statistics.&lt;/p&gt;

&lt;p&gt;For those who are not familiar with non-central distributions, they are the general family of distributions to which the distributions we are familiar with belong. For example, the $t$-test assumes a nil (zero) null effect so we use the non-central $t$-distribution, with an expected value (and non-centrality parameter) of zero. This distribution is what we call the $t$-distribution. If we want to create confidence intervals without assuming a nil effect, we can actually use a $t$-distribution while specifying its non-centrality parameter $(\lambda)$. It is the distribution when the null of zero is false. The &lt;a href=&#34;https://en.wikipedia.org/wiki/Noncentral_t-distribution&#34; target=&#34;_blank&#34;&gt;Wikipedia introduction to this topic for the $t$-distribution&lt;/a&gt; is decent.&lt;/p&gt;

&lt;p&gt;So how does this help us? The non-centrality parameter $(\lambda)$ for the RMSEA test in lavaan is actually the $\chi^2-df$ value that corresponds to an RMSEA of .05. In math:&lt;/p&gt;

&lt;p&gt;$RMSEA = \sqrt{\frac{\chi^2-df}{df(N-1)}}$&lt;/p&gt;

&lt;p&gt;$RMSEA^2 = \frac{\chi^2-df}{df(N-1)}$&lt;/p&gt;

&lt;p&gt;$RMSEA^2 \times df(N-1) = \chi^2-df$&lt;/p&gt;

&lt;p&gt;Since $\chi^2-df$ is $\lambda$, then:&lt;/p&gt;

&lt;p&gt;$\lambda = RMSEA^2 \times df(N-1)$&lt;/p&gt;

&lt;p&gt;So for a test of close fit, $\lambda$ is:&lt;/p&gt;

&lt;p&gt;$RMSEA^2 \times df(N-1) = .05^2 \times df(N-1) = .0025 \times df(N-1)$&lt;/p&gt;

&lt;p&gt;And for a test of mediocre fit, $\lambda$ is:&lt;/p&gt;

&lt;p&gt;$RMSEA^2 \times df(N-1) = .08^2 \times df(N-1) = .0064 \times df(N-1)$&lt;/p&gt;

&lt;p&gt;Note that lavaan may do things a little differently.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Hence, given a model degrees of freedom, and sample size, we can calculate the non-centrality parameter $(\lambda)$. And given $\lambda$, a $\chi^2$ value and the degrees of freedom for the model, we can calculate the p-value for a test of close or mediocre fit.&lt;/p&gt;

&lt;p&gt;The R syntax for this is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pchisq(Chi-sq-value, degrees-of-freedom, non-centrality-parameter, FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;div id=&#34;lavaan&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;demonstration&#34;&gt;Demonstration&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(lavaan)
data(&amp;quot;HolzingerSwineford1939&amp;quot;)
# model syntax for a bifactor model with the HolzingerSwineford1939 dataset
# eliminating visual factor resolves Heywood case
writeLines(syntax &amp;lt;- paste(
  paste(&amp;quot;g =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 1:9, collapse = &amp;quot; + &amp;quot;)),
  # paste(&amp;quot;visual =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 1:3, collapse = &amp;quot; + &amp;quot;)),
  paste(&amp;quot;textual =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 4:6, collapse = &amp;quot; + &amp;quot;)),
  paste(&amp;quot;speed =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 7:9, collapse = &amp;quot; + &amp;quot;)),
  sep = &amp;quot;\n&amp;quot;
))

g =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9

# Run model &amp;amp; report fit measures
# Reporting only fit statistics relevant to this demonstration
summary(hs.fit &amp;lt;- cfa(syntax, HolzingerSwineford1939, std.lv = TRUE,
                      orthogonal = TRUE), fit.measures = TRUE)

lavaan (0.5-23.1097) converged normally after  25 iterations

  Number of observations                           301

  Estimator                                         ML
  Minimum Function Test Statistic               42.291
  Degrees of freedom                                21
  P-value (Chi-square)                           0.004

Root Mean Square Error of Approximation:

  RMSEA                                          0.058
  90 Percent Confidence Interval          0.032  0.083
  P-value RMSEA &amp;lt;= 0.05                          0.276

# Chi-square is statistically significant, this test of perfect fit suggests
# the misfit between our model-implied cov matrix and sample cov matrix is
# greater than expected due to sampling variability.

# The default Chi-square test:

pchisq(q = 42.291, df = 21, ncp = 0, lower.tail = FALSE)

[1] 0.003867178

# Use formula above to calculate non-centrality parameter for test of close fit
# .0025 multiplied by model degrees of freedom by sample size - 1

(ncp.close &amp;lt;- .0025 * 21 * (301 - 1))

[1] 15.75

# Calculate Chi-square test of close fit

pchisq(q = 42.291, df = 21, ncp = ncp.close, lower.tail = FALSE)

[1] 0.2740353

# The p-value for a test of close fit is .27, close to the value reported by
# lavaan. The reason they are not closer is that lavaan does not subtract 1
# from the sample size when calculating the non-centrality parameter under
# its default settings for ML. See the final footnote below for details.

# And if we lower our standards to conduct a chi-square test of mediocre fit:
# .0064 multiplied by model degrees of freedom by sample size - 1

(ncp.med &amp;lt;- .0064 * 21 * (301 - 1))

[1] 40.32

pchisq(q = 42.291, df = 21, ncp = ncp.med, lower.tail = FALSE)

[1] 0.9199686

# If we assume mediocre misspecification in our model, the probability of
# observing our model-implied covariance matrix is 92%. Pretty good.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In closing, SEM practitioners typically report the $\chi^2$-test, but routinely expect the test to detect model misspecification, so often ignore it in practice. I hope the steps above show how one can conduct $\chi^2$-tests that assume some degree of model misspecification as the null hypothesis. I guess I hope that by doing this, we can make our $\chi^2$-tests somewhat relevant. The nice thing about the RMSEA and CI lavaan provides is that together, they may be more informative than a p-value from a $\chi^2$ test.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;P.S.: Another approach to latent variable modeling is PLS path modeling. It is a method for SEMs based on OLS regression. It stems from the work of Hermann Wold. Wold was Joreskog&amp;rsquo;s (LISREL) advisor, Joreskog was Muthen&amp;rsquo;s (Mplus) advisor. This is why my title uses &lt;em&gt;covariance-based SEM&lt;/em&gt; instead of &lt;em&gt;latent variable models&lt;/em&gt; or just &lt;em&gt;SEMs&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;MacCallum, R. C., Browne, M. W., &amp;amp; Sugawara, H. M. (1996). Power analysis and determination of sample size for covariance structure modeling. &lt;em&gt;Psychological Methods, 1&lt;/em&gt;(2), 130–149. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.1.2.130&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1037/1082-989X.1.2.130&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;I always thought mediocre meant a bad thing, it only means unexceptional, ordinary.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;I got this unoriginal idea from discussing with one of my colleagues, Menglin Xu. We were chatting around 11 pm in the office and she mentioned the non-central $\chi^2$ distribution in SEMs. Given my interest in non-central distributions in relation to &lt;a href=&#34;https://effect-size-calculator.herokuapp.com/&#34; target=&#34;_blank&#34;&gt;confidence intervals for effect sizes&lt;/a&gt;, this idea came to mind.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;I found out by digging around &lt;a href=&#34;https://github.com/cran/lavaan/blob/d7bdae575dd78d5ac518e30f84ccfb57023819af/R/lav_fit_measures.R&#34; target=&#34;_blank&#34;&gt;this page&lt;/a&gt; and calculating in R. I continued exploring and noticed lavaan using $N$ only happens with ML estimation. If you try WLSMV estimation, lavaan uses $N-1$; and I got very confused on noticing this and emailed one of my factor analysis professors, Paul De Boeck. He replied in an email mentioning Wishart, bias correction and the lavaan manual. From the lavaan manual, lavaan&amp;rsquo;s default for ML estimation is something it refers to as the &lt;em&gt;normal likelihood approach&lt;/em&gt;. When it does this, it uses $N$. If you change it to the &lt;em&gt;wishart likelihood approach&lt;/em&gt; by specifying &lt;code&gt;likelihood = &amp;quot;wishart&amp;quot;&lt;/code&gt; within the &lt;code&gt;sem()&lt;/code&gt;, &lt;code&gt;cfa()&lt;/code&gt; or &lt;code&gt;lavaan()&lt;/code&gt; functions, it then uses $N-1$. This is only relevant for ML estimation. For other estimation methods, it&amp;rsquo;s $N-1$. I spent a few hours learning about the problem then trying to figure out what was going on, and I got an email reply within minutes of emailing my professor :). &lt;a href=&#34;http://lavaan.ugent.be/tutorial/est.html&#34; target=&#34;_blank&#34;&gt;From the lavaan website on Wishart versus Normal&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Intro to R</title>
      <link>https://www.jamesuanhoro.com/talk/intro-to-r-rmc/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/talk/intro-to-r-rmc/</guid>
      <description>&lt;!-- Material prepared for a full-day Intro to R workshop --&gt;
</description>
    </item>
    
    <item>
      <title>Misspecification and fit indices in covariance-based SEM</title>
      <link>https://www.jamesuanhoro.com/post/testing-covariance-based-sems/</link>
      <pubDate>Sat, 28 Oct 2017 10:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/testing-covariance-based-sems/</guid>
      <description>

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;If you have good measurement quality, conventional benchmarks for fit indices may lead to bad decisions. Additionally, global fit indices are not informative for investigating misspecification.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;I am working with one of my professors, &lt;a href=&#34;http://statsineducation.tumblr.com/&#34; target=&#34;_blank&#34;&gt;Dr. Jessica Logan&lt;/a&gt;, on a checklist for the developmental progress of young children. We intend to take this down the IRT route (or ordinal logistic regression), but currently, this is all part of a factor analysis course project. So I ran some CFA models, and was discussing model fit with Dr. Logan. I commented that factor loadings were generally high (1st quartile = .80, M/Mdn = .84), but initial model fit was inadequate to play the model fit game, for example, RMSEA &amp;gt; .06, &amp;hellip; She commented that she was not so worried by this combination: high loadings together with failure to meet conventional model fit guidelines. And pointed me towards a recent paper by Dan McNeish, Ji An and Gregory Hancock,&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; hereafter &lt;em&gt;MAH&lt;/em&gt;, - the paper is available on &lt;a href=&#34;https://www.researchgate.net/publication/311536084_The_Thorny_Relation_between_Measurement_Quality_and_Fit_Index_Cut-Offs_in_Latent_Variable_Models&#34; target=&#34;_blank&#34;&gt;ResearchGate&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;MAH&amp;rsquo;s argument hinges on an important point: all models are usually misspecified in practice. Counterintuitively, holding misspecification constant, models with lower factor loadings (or poorer measurement quality) have better fit indices than models with higher factor loadings. For example, if two models have the same level of misspecification, and one with factor loadings of .9 could have RMSEA higher than .2, and a model with factor loadings of .4 could have RMSEA less than .05. The paper contains some charts that communicate these results very clearly.&lt;/p&gt;

&lt;p&gt;And this is why in their conclusion, MAH write:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;By comparison, if one is researching a construct for which very high measurement quality can be obtained, one need not subscribe to such stringent AFI criteria to be confident that the model features any nontrivial misspecifications. Conversely, if one is researching a construct that cannot be measured very reliably, the currently employed cutoffs are not suitable and would be very likely to overlook potentially meaningful misspecifications in the model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;AFIs&lt;/code&gt; are approximate goodness of fit indices, these include absolute fit indices like the RMSEA and SRMR, and relative fit indices like CFI.&lt;/p&gt;

&lt;h3 id=&#34;an-alternative-to-working-with-global-fit-indices&#34;&gt;An alternative to working with global fit indices&lt;/h3&gt;

&lt;p&gt;The fit indices MAH write about are global fit indices (hereafter GFIs) and they detect all types of model misspecifications. However, as MAH point out, not all model misspecifications are problematic. Consider order effects, two items may have correlated errors independent of their shared factor simply because one follows the other (serial correlation). The absence of this correlated error in a CFA (the default) would negatively impact any global fit index. Moreover, global fit indices do not tell you what your model misspecifications are.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The sections that follow may include details that not everyone would like to read about, you can skip to the &lt;a href=&#34;#lavaan&#34;&gt;bottom of the page for annotated lavaan code&lt;/a&gt; for what to do instead of using global fit indices.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;MAH reference a 2009 paper by Satis, Satorra and van der Veld,&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; hereafter &lt;em&gt;SSV&lt;/em&gt;, that addresses this issue. SSV laid out a method for investigating model misspecifications that involves the use of modification indices (MI), expected parameter change (EPC), theory and power analysis. The EPC is the value by which a constrained relationship would change from zero if it was freed to be estimated by the model. I believe researchers are familiar with MIs and often use them to fix model misspecifications with the aim of obtaining GFIs that their reviewers will accept. The relationship between MI and EPC is:&lt;/p&gt;

&lt;p&gt;$MI = (EPC/\sigma)^2$&lt;/p&gt;

&lt;p&gt;where $\sigma$ is the standard error of the EPC.&lt;/p&gt;

&lt;p&gt;SSV suggest the following framework:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;specify an unacceptable level of model misspecification $(\delta)$ for any constrained relationship in your model. They recommend thinking about your context, or:

&lt;ul&gt;
&lt;li&gt;for factor loadings, absolute value &amp;gt; .4&lt;/li&gt;
&lt;li&gt;for correlated errors, absolute value &amp;gt; .1&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;calculate a noncentrality parameter, $ncp=(\delta/\sigma)^2$&lt;/li&gt;
&lt;li&gt;this $ncp$ follows a noncental-$\chi^2$ distribution which you can use to calculate the statistical power to detect $\delta$, the unnaceptable degree of model misspecification, for each constrained relationship.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;div id=&#34;lavaan&#34;&gt;&lt;/p&gt;

&lt;p&gt;Next, the following decision rules:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/gfis/dec_rules.png&#34; alt=&#34;Decision rules&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The nice thing is this is all implemented in &lt;code&gt;lavaan&lt;/code&gt; in R. Misspecification codes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Model misspecification: &lt;code&gt;(m)&lt;/code&gt;, &lt;code&gt;(EPC:m)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;No model misspecification: &lt;code&gt;(nm)&lt;/code&gt;, &lt;code&gt;(EPC:nm)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Inconclusive on model misspecification: &lt;code&gt;(i)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(lavaan)
# For this, I&#39;ll assume HolzingerSwineford1939 data are 9 questions, and the
# respondents answered them x1 to x9 sequentially
data(&amp;quot;HolzingerSwineford1939&amp;quot;)
# model syntax for HolzingerSwineford1939 dataset
(syntax &amp;lt;- paste(
  paste(&amp;quot;f1 =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 1:3, collapse = &amp;quot; + &amp;quot;)),
  paste(&amp;quot;f2 =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 4:6, collapse = &amp;quot; + &amp;quot;)),
  paste(&amp;quot;f3 =~&amp;quot;, paste0(&amp;quot;x&amp;quot;, 7:9, collapse = &amp;quot; + &amp;quot;)),
  sep = &amp;quot;\n&amp;quot;))

[1] &amp;quot;f1 =~ x1 + x2 + x3\nf2 =~ x4 + x5 + x6\nf3 =~ x7 + x8 + x9&amp;quot;

# Run model, standardize latent variables, &amp;amp; report standardized results
summary(hs.fit &amp;lt;- cfa(syntax, HolzingerSwineford1939, std.lv = TRUE),
        standardize = TRUE)

lavaan (0.5-23.1097) converged normally after  22 iterations

  Number of observations                           301

  Estimator                                         ML
  Minimum Function Test Statistic               85.306
  Degrees of freedom                                24
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Information                                 Expected
  Standard Errors                             Standard

Latent Variables:
                   Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
  f1 =~                                                                 
    x1                0.900    0.081   11.127    0.000    0.900    0.772
    x2                0.498    0.077    6.429    0.000    0.498    0.424
    x3                0.656    0.074    8.817    0.000    0.656    0.581
  f2 =~                                                                 
    x4                0.990    0.057   17.474    0.000    0.990    0.852
    x5                1.102    0.063   17.576    0.000    1.102    0.855
    x6                0.917    0.054   17.082    0.000    0.917    0.838
  f3 =~                                                                 
    x7                0.619    0.070    8.903    0.000    0.619    0.570
    x8                0.731    0.066   11.090    0.000    0.731    0.723
    x9                0.670    0.065   10.305    0.000    0.670    0.665

Covariances:
                   Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
  f1 ~~                                                                 
    f2                0.459    0.064    7.189    0.000    0.459    0.459
    f3                0.471    0.073    6.461    0.000    0.471    0.471
  f2 ~~                                                                 
    f3                0.283    0.069    4.117    0.000    0.283    0.283

Variances:
                   Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
   .x1                0.549    0.114    4.833    0.000    0.549    0.404
   .x2                1.134    0.102   11.146    0.000    1.134    0.821
   .x3                0.844    0.091    9.317    0.000    0.844    0.662
   .x4                0.371    0.048    7.778    0.000    0.371    0.275
   .x5                0.446    0.058    7.642    0.000    0.446    0.269
   .x6                0.356    0.043    8.277    0.000    0.356    0.298
   .x7                0.799    0.081    9.823    0.000    0.799    0.676
   .x8                0.488    0.074    6.573    0.000    0.488    0.477
   .x9                0.566    0.071    8.003    0.000    0.566    0.558
    f1                1.000                               1.000    1.000
    f2                1.000                               1.000    1.000
    f3                1.000                               1.000    1.000

# Chi-square is statistically significant, there is at least some misfit

# Request modification indices. Sort them from highest to lowest
# Do not print any MI below 3 for convenience of presentation
# Apply SSV method by requesting power = TRUE, and setting delta.
# delta for those who skipped is unacceptable level of misfit, so a delta = .4
# standard for factor loadings means I care about the factor loading if it is
# missing from my model and its factor loading is greater than .4
# By default, delta = .1 in lavaan. Based on SSV&#39;s recommendations, this is
# adequate for correlated errors. So I select only correlated errors for output
# using op = &amp;quot;~~&amp;quot;
modificationindices(hs.fit, sort. = TRUE, minimum.value = 3, power = TRUE,
                    op = &amp;quot;~~&amp;quot;)


lhs op rhs        mi    epc sepc.all delta   ncp power decision
30  f1 =~  x9 36.411  0.519    0.515   0.1 1.351 0.213  **(m)**
76  x7 ~~  x8 34.145  0.536    0.488   0.1 1.187 0.193  **(m)**
28  f1 =~  x7 18.631 -0.380   -0.349   0.1 1.294 0.206  **(m)**
78  x8 ~~  x9 14.946 -0.423   -0.415   0.1 0.835 0.150  **(m)**
33  f2 =~  x3  9.151 -0.269   -0.238   0.1 1.266 0.203  **(m)**
55  x2 ~~  x7  8.918 -0.183   -0.143   0.1 2.671 0.373  **(m)**
31  f2 =~  x1  8.903  0.347    0.297   0.1 0.741 0.138  **(m)**
51  x2 ~~  x3  8.532  0.218    0.164   0.1 1.791 0.268  **(m)**
59  x3 ~~  x5  7.858 -0.130   -0.089   0.1 4.643 0.577  **(m)**
26  f1 =~  x5  7.441 -0.189   -0.147   0.1 2.087 0.303  **(m)**
50  x1 ~~  x9  7.335  0.138    0.117   0.1 3.858 0.502  **(m)**
65  x4 ~~  x6  6.221 -0.235   -0.185   0.1 1.128 0.186  **(m)**
66  x4 ~~  x7  5.920  0.098    0.078   0.1 6.141 0.698  **(m)**
48  x1 ~~  x7  5.420 -0.129   -0.102   0.1 3.251 0.438  **(m)**
77  x7 ~~  x9  5.183 -0.187   -0.170   0.1 1.487 0.230  **(m)**
36  f2 =~  x9  4.796  0.137    0.136   0.1 2.557 0.359  **(m)**
29  f1 =~  x8  4.295 -0.189   -0.187   0.1 1.199 0.195  **(m)**
63  x3 ~~  x9  4.126  0.102    0.089   0.1 3.993 0.515  **(m)**
67  x4 ~~  x8  3.805 -0.069   -0.059   0.1 7.975 0.806     (nm)
43  x1 ~~  x2  3.606 -0.184   -0.134   0.1 1.068 0.178      (i)
45  x1 ~~  x4  3.554  0.078    0.058   0.1 5.797 0.673      (i)
35  f2 =~  x8  3.359 -0.120   -0.118   0.1 2.351 0.335      (i)

# Check the decision column
# x7 and x8 is termed misspecification because power is low at .193, yet the MI
# is statistically significant. However, this may simply be due to order
# effects, and such misspecification can be acceptable. I will not add this
# correlated error to my model. Same goes for x8 and x9 (lhs 78) and x2 and x3
# (lhs 51). These missing serial-correlations are acceptable misspecifications.

# However consider x2 and x7 (lhs 55), low power at .373 yet significant MI.
# Is there some theory connecting these two items? Can I explain the
# suggested correlation?

# Consider x4 and x8 (lhs 67), high power at .806, yet the MI is not
# statistically significant, hence we can conclude there is no misspecification.

# Consider x1 and x4 (lhs 45), low power at .673, and the MI is not
# statistically significant, hence this is inconclusive.

# Now for the factor loadings
modificationindices(hs.fit, sort. = TRUE, power = TRUE, delta = .4, op = &amp;quot;=~&amp;quot;)

lhs op rhs        mi    epc sepc.all delta    ncp power decision
30  f1 =~  x9 36.411  0.519    0.515   0.4 21.620 0.996  *epc:m*
28  f1 =~  x7 18.631 -0.380   -0.349   0.4 20.696 0.995   epc:nm
33  f2 =~  x3  9.151 -0.269   -0.238   0.4 20.258 0.994   epc:nm
31  f2 =~  x1  8.903  0.347    0.297   0.4 11.849 0.931   epc:nm
26  f1 =~  x5  7.441 -0.189   -0.147   0.4 33.388 1.000   epc:nm
36  f2 =~  x9  4.796  0.137    0.136   0.4 40.904 1.000   epc:nm
29  f1 =~  x8  4.295 -0.189   -0.187   0.4 19.178 0.992   epc:nm
35  f2 =~  x8  3.359 -0.120   -0.118   0.4 37.614 1.000     (nm)
27  f1 =~  x6  2.843  0.100    0.092   0.4 45.280 1.000     (nm)
38  f3 =~  x2  1.580 -0.123   -0.105   0.4 16.747 0.984     (nm)
25  f1 =~  x4  1.211  0.069    0.059   0.4 40.867 1.000     (nm)
39  f3 =~  x3  0.716  0.084    0.075   0.4 16.148 0.980     (nm)
42  f3 =~  x6  0.273  0.027    0.025   0.4 58.464 1.000     (nm)
41  f3 =~  x5  0.201 -0.027   -0.021   0.4 43.345 1.000     (nm)
34  f2 =~  x7  0.098 -0.021   -0.019   0.4 36.318 1.000     (nm)
32  f2 =~  x2  0.017 -0.011   -0.010   0.4 21.870 0.997     (nm)
37  f3 =~  x1  0.014  0.015    0.013   0.4  9.700 0.876     (nm)
40  f3 =~  x4  0.003 -0.003   -0.003   0.4 52.995 1.000     (nm)


# See the first line, suggesting I load x9 on f1. The power is high, the MI is
# significant and the EPC is higher than .4 suggesting that this is some type
# of misspecification that we should pay attention to.

# However, the next line suggests I load x7 on f1. The power is high, the MI is
# significant, but the EPC is .38, less than .4, suggesting that we do not
# consider this misspecification to be high enough to warrant modifying the
# model. Same goes for a number of suggested modifications with decision epc:nm.

# Then there is a final group with high power, but the MIs are not
# statistically significant, so we can conclude there is no misspecification.

# Note that you can also tell lavaan what constitutes high power using the
# `high.power = ` argument. 75% is what SSV use and lavaan&#39;s default but you
# can be flexible.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that you make only one change to the model at a time. The EPC and MI, are calculated assuming other parameters are approximately correct, hence the way to run the steps above is to make one change, then re-request the MIs, EPC, and power from &lt;code&gt;lavaan&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I believe this is the approach recommended by SSV, and following this approach would cause one to think about the model when using MIs, while taking statistical power to detect misspecification into account. It is possible to resolve all the non-inconclusive relationships (using theory, modifications, &amp;hellip;) and be left with a model where you do not have the power to detect the remaining misspecifications (a bunch of inconclusives). This would be another reason to reduce our confidence in our final modeling results.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;P.S.: Another approach to latent variable modeling is PLS path modeling. It is a method for SEMs based on OLS regression. It stems from the work of Hermann Wold. Wold was Joreskog&amp;rsquo;s (LISREL) advisor, Joreskog was Muthen&amp;rsquo;s (Mplus) advisor. This is why my title uses &lt;em&gt;covariance-based SEM&lt;/em&gt; instead of &lt;em&gt;latent variable models&lt;/em&gt; or just &lt;em&gt;SEMs&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;McNeish, D., An, J., &amp;amp; Hancock, G. R. (2017). The Thorny Relation Between Measurement Quality and Fit Index Cutoffs in Latent Variable Models. &lt;em&gt;Journal of Personality Assessment&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1080/00223891.2017.1281286&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1080/00223891.2017.1281286&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Saris, W. E., Satorra, A., &amp;amp; van der Veld, W. M. (2009). Testing Structural Equation Models or Detection of Misspecifications? &lt;em&gt;Structural Equation Modeling: A Multidisciplinary Journal, 16&lt;/em&gt;(4), 561–582. &lt;a href=&#34;https://doi.org/10.1080/10705510903203433&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1080/10705510903203433&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Theil-Sen regression in R</title>
      <link>https://www.jamesuanhoro.com/post/theil-sen-regression/</link>
      <pubDate>Thu, 21 Sep 2017 13:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/theil-sen-regression/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;When performing a simple linear regression, if you have any concern about outliers or heterosedasticity, consider the &lt;code&gt;Theil-Sen estimator&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;A simple linear regression estimator that is not commonly used or taught in the social sciences is the Theil-Sen estimator. This is a shame given that this estimator is very intuitive, once you know what a slope means. Three steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Plot a line between all the points in your data&lt;/li&gt;
&lt;li&gt;Calculate the slope for each line&lt;/li&gt;
&lt;li&gt;The median slope is your regression slope&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Calculating the slope this way happens to be quite robust. And when the errors are normally distributed and you have no outliers, the slope is very similar to OLS.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;There are several methods to obtain the intercept. It is reasonable to know what your software is doing if you care for the intercept in your regression. Theil-Sen regression is available in two R packages I know of: &lt;code&gt;WRS&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/mblm/index.html&#34; target=&#34;_blank&#34;&gt;mblm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mblm&lt;/code&gt; includes a modification to Theil&amp;rsquo;s original method that has a higher breakdown point (more robust).&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; This modification is the default method.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;WRS&lt;/code&gt; contains two functions for Theil-Sen regression: Theil&amp;rsquo;s original method in the &lt;code&gt;tsreg&lt;/code&gt; function, and a modification for small samples when there are tied values in the outcome in the &lt;code&gt;tshdreg&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;Re my comment at the top regarding Theil-Sen for simple linear regression when there are concerns about outliers and heteroscedasticity, see Dietz&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; and Wilcox&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; below.&lt;/p&gt;

&lt;p&gt;I conducted a &lt;a href=&#34;https://www.jamesuanhoro.com/misc/scripts/ts_sim.R&#34;&gt;toy simulation&lt;/a&gt; to see how Theil-Sen competes with OLS under heteroscedasticity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/ts_hetero/0_slopes_hetero.png&#34; alt=&#34;Simulation results&#34; /&gt;
&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/ts_hetero/0_heteroscedastic_samples.png&#34; alt=&#34;25 random samples from simulation&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Wilcox, R. R. (1998). A note on the Theil-Sen regression estimator when the regressor is random and the error term is heteroscedastic. &lt;em&gt;Biometrical Journal, 40&lt;/em&gt;(3), 261–268. &lt;a href=&#34;https://doi.org/10.1002/(SICI)1521-4036(199807)40:3&amp;lt;261::AID-BIMJ261&amp;gt;3.0.CO;2-V&#34; target=&#34;_blank&#34;&gt;doi: 10.1002/(SICI)1521-4036(199807)40:3&amp;lt;261::AID-BIMJ261&amp;gt;3.0.CO;2-V&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;&lt;strong&gt;W&lt;/strong&gt;ilcox &lt;strong&gt;R&lt;/strong&gt;obust &lt;strong&gt;S&lt;/strong&gt;tatistics - Rand Wilcox&amp;rsquo;s collection of robust methods. It is not available on CRAN, as CRAN requires proper documentation for all functions. This is a good set of installation instructions - &lt;a href=&#34;https://web.archive.org/web/20170712140359/http://www.nicebread.de/installation-of-wrs-package-wilcox-robust-statistics/&#34; target=&#34;_blank&#34;&gt;https://web.archive.org/web/20170712140359/http://www.nicebread.de/installation-of-wrs-package-wilcox-robust-statistics/&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Siegel, A. F. (1982). Robust regression using repeated medians. &lt;em&gt;Biometrika, 69&lt;/em&gt;(1), 242–244. &lt;a href=&#34;https://doi.org/10.1093/biomet/69.1.242&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1093/biomet/69.1.242&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Dietz, E. J. (1987). A comparison of robust estimators in simple linear regression. Communications in Statistics - Simulation and Computation, 16(4), 1209–1227. &lt;a href=&#34;https://doi.org/10.1080/03610918708812645&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1080/03610918708812645&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;Wilcox, R. R. (1998). A note on the Theil-Sen regression estimator when the regressor is random and the error term is heteroscedastic. Biometrical Journal, 40(3), 261–268.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Little&#39;s MCAR test at different sample sizes</title>
      <link>https://www.jamesuanhoro.com/post/little-mcar-sample-sizes/</link>
      <pubDate>Thu, 21 Sep 2017 10:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/little-mcar-sample-sizes/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;Little&amp;rsquo;s MCAR test is unable to tell data that are MCAR from data that are MAR in small samples, but maintains the nominal error rate when null is true across a wide range of sample sizes.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;I just found out about the R &lt;a href=&#34;https://cran.r-project.org/web/packages/simglm/index.html&#34; target=&#34;_blank&#34;&gt;simglm package&lt;/a&gt; and decided to do a small simulation to test Little&amp;rsquo;s MCAR test&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; under different sample sizes. I could have investigated heteroskedasticity in linear regression instead, and I probably will in the future. I was able to find some examples of researchers using Little&amp;rsquo;s MCAR test at small sample sizes, so I ran a toy simulation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/little_mcar/zoom_in.png&#34; alt=&#34;Data are MCAR&#34; /&gt;
&lt;img src=&#34;https://www.jamesuanhoro.com/img/posts/little_mcar/zoom_in_mar.png&#34; alt=&#34;Data are MAR&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And this is the &lt;a href=&#34;https://www.jamesuanhoro.com/misc/scripts/little_sim.R&#34;&gt;script I used&lt;/a&gt;, the underlying regression is near perfect (no multicollinearity).&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Little, R. J. A. (1988). A Test of Missing Completely at Random for Multivariate Data with Missing Values. &lt;em&gt;Journal of the American Statistical Association, 83&lt;/em&gt;(404), 1198. &lt;a href=&#34;https://doi.org/10.2307/2290157&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.2307/2290157&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Linear regression with violation of heteroskedasticity with small samples</title>
      <link>https://www.jamesuanhoro.com/post/regression-heteroskedasticity-small-samples/</link>
      <pubDate>Tue, 19 Sep 2017 10:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/regression-heteroskedasticity-small-samples/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;In small samples, the &lt;code&gt;wild bootstrap&lt;/code&gt; implemented in the R &lt;code&gt;hcci&lt;/code&gt; package is a good bet when heteroskedasticity is a concern.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Today while teaching the multiple regression lab, I showed the class the standardized residuals versus standardized predictor plot SPSS lets you produce. It is the plot we typically use to assess homoskedasticity. The sample size for the analysis was 44. I mentioned how the regression slopes are fine under heteroskedasticity, but inference $(t,SE,pvalue)$ may be problematic. Supplemental R material I created included how to use the &lt;code&gt;sandwich&lt;/code&gt; package to obtain heteroskedasticity-consistent standard errors (HCSEs). And after applying HC3 (or any of the HCs from 1 to 5), a regression coefficient was no longer statistically significant at $\alpha=.05$.&lt;/p&gt;

&lt;p&gt;I mentioned to the class that some folks would recommend applying HCSEs by default. After class, I tried to learn about the difference between the different HCs. The following papers were helpful: Zeileis (2004),&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; Long &amp;amp; Ervin (2000),&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; Cribari-Neto, Souza &amp;amp; Vasconcellos (2007),&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; and Hausman &amp;amp; Palmer (2012)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. The &lt;a href=&#34;https://cran.r-project.org/web/packages/sandwich/index.html&#34; target=&#34;_blank&#34;&gt;documentation for the sandwich package&lt;/a&gt; was a big help. The Hausman &amp;amp; Palmer (H&amp;amp;P) paper is probably best if you&amp;rsquo;re only going to read one of the papers, and it can also serve as a short handy reference for dealing with heteroskedasticity at small sample sizes.&lt;/p&gt;

&lt;p&gt;I learned that &lt;strong&gt;HCSEs can be problematic (H&amp;amp;P Table 1)&lt;/strong&gt;. Additionally, the &lt;strong&gt;Wild Bootstrap does a good job of maintaining the nominal error rate in small samples (&lt;em&gt;n=40&lt;/em&gt;) under homoskedasticity, moderate heteroskedasticity and severe heteroskedasticity (H&amp;amp;P Table 1). It is also statistically powerful (H&amp;amp;P Fig. 1 &amp;amp; 2)&lt;/strong&gt;. The good thing is the &lt;a href=&#34;https://cran.r-project.org/web/packages/hcci/index.html&#34; target=&#34;_blank&#34;&gt;hcci package&lt;/a&gt; contains a function called &lt;code&gt;Pboot()&lt;/code&gt; which performs the wild bootstrap to correct for heteroskedasticity.&lt;/p&gt;

&lt;p&gt;As far as I see, the function has one limitation: when you perform your regression, you cannot use the optional dataframe argument in &lt;code&gt;lm()&lt;/code&gt;. Here&amp;rsquo;s an example with &lt;a href=&#34;https://www.jamesuanhoro.com/misc/datasets/atlschools.csv&#34;&gt;this dataset&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(hcci)
atlschools &amp;lt;- read.csv(&amp;quot;./atlschools.csv&amp;quot;)
# You can not pass the dataframe to the Pboot function so the next few lines are required prior to calling lm()
ppc &amp;lt;- atlschools$PPC # per-pupil costs
ptr_c &amp;lt;- scale(atlschools$PTR, scale = FALSE) # pupil/teacher ratio
mts_c_10 &amp;lt;- scale(atlschools$MTS, scale = FALSE) / 10 # monthly teacher salary

coef(summary(fit.0 &amp;lt;- lm(ppc ~ ptr_c + mts_c_10)))
             Estimate Std. Error   t value     Pr(&amp;gt;|t|)
(Intercept) 67.884318  1.1526357 58.894861 3.017231e-41
ptr_c       -2.798285  0.3685282 -7.593138 2.427617e-09
mts_c_10     2.477010  0.8167532  3.032752 4.190607e-03

Pboot(model = fit.0, J = 1000, K = 100)

$beta
[1] 67.884318 -2.798285  2.477010

$ci_lower_simple
[1] 65.5454924 -3.7301276 -0.0653991

$ci_upper_simple
[1] 70.221038 -1.904783  4.969260
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The CI of monthly teacher salary includes 0, evidence to suggest we cannot distinguish its slope from 0. The inference at $\alpha=.05$ is different from OLS.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Zeileis, A. (2004). Econometric Computing with HC and HAC Covariance Matrix Estimators. &lt;em&gt;Journal of Statistical Software, 11&lt;/em&gt;(10). &lt;a href=&#34;https://doi.org/10.18637/jss.v011.i10&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.18637/jss.v011.i10&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Long, J. S., &amp;amp; Ervin, L. H. (2000). Using Heteroscedasticity Consistent Standard Errors in the Linear Regression Model. &lt;em&gt;The American Statistician, 54&lt;/em&gt;(3), 217–224. &lt;a href=&#34;https://doi.org/10.1080/00031305.2000.10474549&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1080/00031305.2000.10474549&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Cribari-Neto, F., Souza, T. C., &amp;amp; Vasconcellos, K. L. P. (2007). Inference Under Heteroskedasticity and Leveraged Data. &lt;em&gt;Communications in Statistics - Theory and Methods, 36&lt;/em&gt;(10), 1877–1888. &lt;a href=&#34;https://doi.org/10.1080/03610920601126589&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1080/03610920601126589&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Hausman, J., &amp;amp; Palmer, C. (2012). Heteroskedasticity-robust inference in finite samples. &lt;em&gt;Economics Letters, 116&lt;/em&gt;(2), 232–235. &lt;a href=&#34;https://doi.org/10.1016/j.econlet.2012.02.007&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.1016/j.econlet.2012.02.007&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>On the interpretation of regression coefficients</title>
      <link>https://www.jamesuanhoro.com/post/interpretation-regression-coefficients/</link>
      <pubDate>Fri, 11 Aug 2017 10:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/post/interpretation-regression-coefficients/</guid>
      <description>

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;We should interpret regression coefficients for continuous variables as we would descriptive dummy variables, unless we intend to make causal claims.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;I am going to be teaching regression labs in the Fall, and somehow, I stumbled onto Gelman and Hill&amp;rsquo;s &lt;em&gt;Data analysis using regression and multilevel/hierarchical models&lt;/em&gt;.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; So I started reading it and it&amp;rsquo;s a good book.&lt;/p&gt;

&lt;p&gt;A useful piece of advice they give is to interpret regression coefficients in a predictive manner (p. 34). To see what they mean, let us consider an example.&lt;/p&gt;

&lt;h2 id=&#34;predicting-student-performance&#34;&gt;Predicting student performance&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ll use a &lt;a href=&#34;https://www.jamesuanhoro.com/misc/datasets/hsb_comb_full.csv&#34;&gt;subset of the High School &amp;amp; Beyond dataset&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hsb &amp;lt;- read.csv(&amp;quot;datasets/hsb_comb_full.csv&amp;quot;)
names(hsb)
[1] &amp;quot;schoolid&amp;quot; &amp;quot;minority&amp;quot; &amp;quot;female&amp;quot;   &amp;quot;ses&amp;quot;      &amp;quot;mathach&amp;quot;  &amp;quot;size&amp;quot;     &amp;quot;sector&amp;quot;   
[8] &amp;quot;pracad&amp;quot;   &amp;quot;disclim&amp;quot;  &amp;quot;himinty&amp;quot;  &amp;quot;MEANSES&amp;quot;  &amp;quot;N_BREAK&amp;quot;  &amp;quot;sesdev&amp;quot;   &amp;quot;myschool&amp;quot;

# Let&#39;s go with the first school, and the first 5 student-level variables
hsb &amp;lt;- hsb[hsb$schoolid == hsb$schoolid[1], 1:5]
summary(hsb)
schoolid       minority           female            ses             mathach      
Min.   :1224   Min.   :0.00000   Min.   :0.0000   Min.   :-1.6580   Min.   :-2.832  
1st Qu.:1224   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:-0.8830   1st Qu.: 3.450  
Median :1224   Median :0.00000   Median :1.0000   Median :-0.4680   Median : 8.296  
Mean   :1224   Mean   :0.08511   Mean   :0.5957   Mean   :-0.4344   Mean   : 9.715  
3rd Qu.:1224   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:-0.0330   3rd Qu.:16.370  
Max.   :1224   Max.   :1.00000   Max.   :1.0000   Max.   : 0.9720   Max.   :23.584  

# Mathach, ses and female seem to have some variability
# Let&#39;s predict math achievement using female (dummy), ses (continuous)
lm(mathach ~ female + ses, hsb)

Call:
lm(formula = mathach ~ female + ses, data = hsb)

Coefficients:
(Intercept)       female          ses  
     12.092       -2.062        2.643  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the typical approach to interpreting the coefficient for &lt;code&gt;female&lt;/code&gt; is:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Holding SES constant, there is on average, a 2.06-point difference in math achievement between males and females, with males performing better.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There is nothing wrong with this approach, however to clarify the language, we could say:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For students with the same SES, we expect a 2.06-point difference in math achievement between males and females, with males performing better.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem arises with the interpretation of &lt;code&gt;ses&lt;/code&gt;, it typically goes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Holding gender constant, a point improvement in SES relates with a 2.64 increase in math achievement.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We typically claim this is a correlational statement, devoid of causal claims. However, it has causal overtones. It insinuates that within an individual, if we could raise their SES by 1 point, we can expect an increase in math achievement by 2.64 points.&lt;/p&gt;

&lt;p&gt;Gelman and Hill advice phrasing its interpretation like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For students of the same gender, we expect a 2.64-point difference in math achievement between students who have a point difference in SES.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is what they call a &lt;em&gt;predictive interpretation&lt;/em&gt; of regression coefficients. It is devoid of causality, and communicates that we are making predictions for or describing the difference between different individuals.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Gelman, A., &amp;amp; Hill, J. (2007). &lt;em&gt;Data analysis using regression and multilevel/hierarchical models&lt;/em&gt;. Cambridge University Press.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data visualization with ggplot2</title>
      <link>https://www.jamesuanhoro.com/talk/ggplot2-festival/</link>
      <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/talk/ggplot2-festival/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Effect size application demo</title>
      <link>https://www.jamesuanhoro.com/talk/es-demo-festival/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/talk/es-demo-festival/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Intro to R</title>
      <link>https://www.jamesuanhoro.com/talk/intro-to-r-pub-pol/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/talk/intro-to-r-pub-pol/</guid>
      <description>&lt;p&gt;Material prepared for a full-day Intro to R workshop&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to SPSS</title>
      <link>https://www.jamesuanhoro.com/talk/intro-to-spss-rmc-0/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/talk/intro-to-spss-rmc-0/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://www.jamesuanhoro.com/workshop/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/workshop/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2010 Nigeria Poverty Profile</title>
      <link>https://www.jamesuanhoro.com/project/nigeria-poverty-profile/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/project/nigeria-poverty-profile/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Canvas LMS Class Visualizations</title>
      <link>https://www.jamesuanhoro.com/project/canvas-lms-visualization/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.jamesuanhoro.com/project/canvas-lms-visualization/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
